# -*- coding: utf-8 -*-
"""ELORA_AI (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//huggingface.co/deathcodes/ELORA/blob/main/ELORA_AI%20(3).ipynb

# Elora AI Assistant - Multi-Modal AI System

A multi-functional AI assistant combining text generation, image synthesis, and OCR capabilities using state-of-the-art models.

## üß† Models Used

### 1. Chatbot: DistilGPT2
**Purpose**: Text generation and conversational AI  
**Architecture**: Distilled version of GPT-2 with 82M parameters (6-layer transformer)  
**Key Features**:
- Lightweight yet powerful text generation
- Maintains 97% of GPT-2's performance with 40% fewer parameters
- Generates contextual responses in real-time

**Implementation**:
- Uses Hugging Face's `transformers` library
- Processes user input with tokenizer
- Generates responses using causal language modeling

### 2. Image Generation: Stable Diffusion v1-4
**Purpose**: Text-to-image synthesis  
**Architecture**: Latent Diffusion Model (LDM) with 890M parameters  
**Key Features**:
- Generates 512x512 images from text prompts
- CLIP-guided diffusion process
- Balanced quality/speed tradeoff

**Implementation**:
- Uses `diffusers` library pipeline
- FP16 precision on CUDA devices for faster inference
- Automatic image saving with UUID filenames

### 3. OCR Engine: Tesseract (via pytesseract)
**Purpose**: Text extraction from images  
**Features**:
- Open-source OCR engine
- Supports multiple languages
- Handles various image formats

**Implementation**:
- Uses `pytesseract` Python wrapper
- Processes both file paths and PIL images
- Fallback message for images without text

### 4. Additional Components
- **gTTS**: Text-to-speech engine (ready for future integration)
- **Gradio**: Web interface builder

## üîÑ Full Pipeline

# üåü Elora AI Workflow Magic üåü

```mermaid
graph TD
    A[üé™ User Interface] --> B{üîÄ Choose Mode}
    
    B --> |üó£Ô∏è Chat Mode| C[üß† DistilGPT2]
    B --> |üé® Generate Mode| D[üñåÔ∏è Stable Diffusion v1-4]
    B --> |üëÅÔ∏è Read Mode| E[üì∏ Tesseract OCR]
    
    C --> F[üí¨ Response Generated]
    D --> G[üåå Image Created]
    E --> H[üìú Text Extracted]
    
    F --> I[üéâ Display Answer]
    G --> J[üñºÔ∏è Show Artwork]
    H --> K[üîç Reveal Text]
    
    style A fill:#FF6B6B,stroke:#333
    style B fill:#4ECDC4,stroke:#333
    style C fill:#45B7D1,stroke:#333
    style D fill:#96CEB4,stroke:#333
    style E fill:#FFEEAD,stroke:#333
    style F,G,H fill:#ffffff,stroke:#DAA520
    style I,J,K fill:#FF9999,stroke:#FF4500
"""

# Install all required packages
!pip install -q transformers diffusers gradio accelerate pytesseract gtts

# Imports
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from diffusers import StableDiffusionPipeline
from PIL import Image
import pytesseract
from gtts import gTTS
from IPython.display import Audio
import gradio as gr
import uuid
import os

# Load chatbot model (DistilGPT2 for light weight)
tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
model = AutoModelForCausalLM.from_pretrained("distilgpt2")
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

# Load Stable Diffusion
pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", torch_dtype=torch.float16 if device=="cuda" else torch.float32)
pipe = pipe.to(device)

# Chatbot function compatible with gr.ChatInterface
def elora_chat(message, history):
    input_text = message
    input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors='pt').to(device)
    output_ids = model.generate(input_ids, max_length=100, pad_token_id=tokenizer.eos_token_id)
    response = tokenizer.decode(output_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)
    return response

# Image generation function
def generate_image(prompt):
    image = pipe(prompt).images[0]
    filename = f"/tmp/gen_{uuid.uuid4().hex}.png"
    image.save(filename)
    return filename

# OCR function
def perform_ocr(image):
    if isinstance(image, str):
        image = Image.open(image)
    text = pytesseract.image_to_string(image)
    return text if text.strip() else "No text detected."

# Gradio UI
with gr.Blocks() as elora_ui:
    gr.Markdown("## üß† Elora AI - Assistant | Text ‚úçÔ∏è + Image üé® + OCR üìñ")

    with gr.Tab("üó£Ô∏è Chatbot"):
        gr.ChatInterface(fn=elora_chat, title="Talk to Elora")

    with gr.Tab("üé® Image Generator"):
        prompt = gr.Textbox(label="Enter prompt")
        gen_btn = gr.Button("Generate")
        image_out = gr.Image(label="Generated Image")
        gen_btn.click(fn=generate_image, inputs=prompt, outputs=image_out)

    with gr.Tab("üìñ OCR Reader"):
        ocr_input = gr.Image(type="filepath", label="Upload Image")
        ocr_btn = gr.Button("Read Text")
        ocr_output = gr.Textbox(label="OCR Result")
        ocr_btn.click(fn=perform_ocr, inputs=ocr_input, outputs=ocr_output)

elora_ui.launch(debug=False)

